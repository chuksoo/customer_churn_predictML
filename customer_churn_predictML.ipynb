{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Customer Churn with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "We need to predict whether a customer will leave the bank soon. You have the data on clients’ past behavior and termination of contracts with the bank. \n",
    "\n",
    "Build a model with the maximum possible F1 score. To pass the project, you need an F1 score of at least 0.59. Check the F1 for the test set. Additionally, measure the AUC-ROC metric and compare it with the F1.\n",
    "Data source: https://code.s3.yandex.net/datasets/Churn.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Business Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key business metrics (along with cash flow etc.) for banks, internet providers, pay TV companies, telecom companies is customer attrition analysis (or customer churn analysis). We say customer churn is loss of clients or customers. It is cheaper to keep existing customers than go for new ones. Beta bank have already seen the effect of customer churn as it affects their end of the year revenue and monthly recurring revenue (or MRR). To this end, we need to predict whether a customer will leave a bank soon given their past relationship and behavior while operating with Beta bank. The bank hopes to deploy churn prediction models and effective retention strategies in managing customer attrition thereby preventing significant loss of revenue from defecting customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the customer data, train a model that predicts whether a customer will leave the bank soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be found in '/datasets/Churn.csv' file. Download the dataset. \n",
    "\n",
    "**Features**\n",
    "\n",
    " - `RowNumber` — data string index\n",
    " - `CustomerId` — unique customer identifier\n",
    " - `Surname` — surname\n",
    " - `CreditScore` — credit score\n",
    " - `Geography` — country of residence\n",
    " - `Gender` — gender\n",
    " - `Age` — age\n",
    " - `Tenure` — period of maturation for a customer’s fixed deposit (years)\n",
    " - `Balance` — account balance\n",
    " - `NumOfProducts` — number of banking products used by the customer\n",
    " - `HasCrCard` — customer has a credit card\n",
    " - `IsActiveMember` — customer’s activeness\n",
    " - `EstimatedSalary` — estimated salary\n",
    "\n",
    "**Target**\n",
    "\n",
    " - `Exited` — сustomer has left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "The objectives of this project is to:\n",
    "- Develop a model that would predicts whether a customer will leave the bank soon\n",
    "- Build a machine learning model with the maximum possible F1 score of atleast 0.59 or higher.\n",
    "- Measure the AUC-ROC metric and compare it with the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    " # Table of contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#open_the_data\">Open the data file and study the general information</a></li>\n",
    "        <li><a href=\"#data_preparation\">Prepare the data</a></li>\n",
    "        <li><a href=\"#feature_engineering\">Feature engineering</a></li>\n",
    "        <li><a href=\"#class_balance\">Examine the balance of classes</a></li>\n",
    "        <li><a href=\"#improve_quality\">Improve the quality of the model</a></li>\n",
    "        <li><a href=\"#investigate_models\">Investigate different models quality</a></li>\n",
    "        <li><a href=\"#check_quality\">Check model quality</a></li>\n",
    "        <li><a href=\"#sanity_check\">Sanity check the model</a></li>\n",
    "        <li><a href=\"#overall_conclusion\">Overall conclusion</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"open_the_data\">\n",
    "    <h2>Open the data file and study the general information</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require the following libraries: *pandas* and *numpy* for data preprocessing and manipulation, *Scikit-Learn* for building our learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project libraries has been successfully been imported!\n"
     ]
    }
   ],
   "source": [
    "# import pandas and numpy for data preprocessing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import train_test_split to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.options.mode.chained_assignment = None # to avoid SettingWithCopyWarning after scaling\n",
    "\n",
    "# import machine learning module from the sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression # import logistic regression \n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier # import adaboost classifier algorithm\n",
    "\n",
    "# import metrics for sanity check on model\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "#from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "# import sklearn utilities\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print('Project libraries has been successfully been imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been read correctly!\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "try:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Supervised Learning/Churn.csv')\n",
    "print('Data has been read correctly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine if columns in file have null values\n",
    "def get_percent_of_na(df, num):\n",
    "    count = 0\n",
    "    df = df.copy()\n",
    "    s = (df.isna().sum() / df.shape[0])\n",
    "    for column, percent in zip(s.index, s.values):\n",
    "        num_of_nulls = df[column].isna().sum()\n",
    "        if num_of_nulls == 0:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        print('Column {} has {:.{}%} percent of Nulls, and {} of nulls'.format(column, percent, num, num_of_nulls))\n",
    "    if count != 0:\n",
    "        print(\"\\033[1m\" + 'There are {} columns with NA.'.format(count) + \"\\033[0m\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\\033[1m\" + 'There are no columns with NA.' + \"\\033[0m\")\n",
    "        \n",
    "# function to display general information about the dataset\n",
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    This function uses the head(), info(), describe(), shape() and duplicated() \n",
    "    methods to display the general information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + '-'*100 + \"\\033[0m\")\n",
    "    print('Head:')\n",
    "    print()\n",
    "    display(df.head())\n",
    "    print('-'*100)\n",
    "    print('Info:')\n",
    "    print()\n",
    "    display(df.info())\n",
    "    print('-'*100)\n",
    "    print('Describe:')\n",
    "    print()\n",
    "    display(df.describe())\n",
    "    print('-'*100)\n",
    "    display(df.describe(include='object'))\n",
    "    print()\n",
    "    print('Columns with nulls:')\n",
    "    display(get_percent_of_na(df, 4))  # check this out\n",
    "    print('-'*100)\n",
    "    print('Shape:')\n",
    "    print(df.shape)\n",
    "    print('-'*100)\n",
    "    print('Duplicated:')\n",
    "    print(\"\\033[1m\" + 'We have {} duplicated rows.\\n'.format(df.duplicated().sum()) + \"\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information about the dataframe\n",
      "\u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Describe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2932</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Smith</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>32</td>\n",
       "      <td>5014</td>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surname Geography Gender\n",
       "count    10000     10000  10000\n",
       "unique    2932         3      2\n",
       "top      Smith    France   Male\n",
       "freq        32      5014   5457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with nulls:\n",
      "Column Tenure has 9.0900% percent of Nulls, and 909 of nulls\n",
      "\u001b[1mThere are 1 columns with NA.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape:\n",
      "(10000, 14)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Duplicated:\n",
      "\u001b[1mWe have 0 duplicated rows.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# study the general information about the dataset \n",
    "print('General information about the dataframe')\n",
    "get_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "From the information about the dataset, we have 10000 rows and 14 features. Looking at the dataset, we can see that about 9% of the data is missing in the `Tenure` column. We should also note that the missing values are *missing at random (MAR)*. To handle this missing values, we could either drop them entirely since the percentage of missing values is less than 10% or replace by the median of the column. Also, we need to correct the datatype from float to int in the `Tenure`, `Balance` and `EstimatedSalary` columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"data_preparation\">\n",
    "    <h2>Prepare the data</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare `Tenure` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replace missing values in the `Tenure` column, we first get the unique values of `Surname`, then get the list of possible `Tenure` for those names. We then choose a random value from the list (excluding the nan values) and assign that to the missing tenure for that surname in the dataframe. For unique surname with an empty list, we use the median of the value in the `Tenure` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values in the Tenure column\n",
    "# get unique values of name from this dataframe\n",
    "for surname in df['Surname'].unique().tolist():\n",
    "    # get specific 'Surname' possible Tenure\n",
    "    specific_surname_df = df[df['Surname'] == surname].dropna()['Tenure']\n",
    "    surname_tenure_list = specific_surname_df.unique().tolist()\n",
    "    # for the missing values, assign a random choice of the tenure for that surname. The default is the median of the 'Tenure'\n",
    "    if surname_tenure_list != []:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = random.choice(surname_tenure_list)\n",
    "    else:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = df['Tenure'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have replaced missing values in the `Tenure` column based on the condition we specified. Let's look at the statistics of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.015900</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.884559</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.015900   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.884559   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the statistics of the new dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to the correct data type\n",
    "def convert_to_type(df, cols, type_val):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_val)\n",
    "        \n",
    "convert_to_type(df, ['Surname', 'Geography', 'Gender'], str)\n",
    "convert_to_type(df, ['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Exited'], 'int64')\n",
    "convert_to_type(df, ['Balance', 'EstimatedSalary'], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't have any missing values and we have changed the datatype in the dataset. Replacing the missing values seems like a better option than dropping the columns with missing values. Care should be taken when replacing missing values. We don't want to create bias or variance in our dataset. The data has been cleaned and so it is ready for feature engineering and machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"feature_engineering\">\n",
    "    <h2>Feature engineering</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we carry out feature engineering and one-hot encoding for the categorical features. We will use one-hot encoding to transform categorical features to numerical features. To do that we have to first create dummy variable and then apply one-hot encoding for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set now contains 6000 observations representing 60% of the data\n",
      "The valid set now contains 2000 observations representing 20% of the data\n",
      "The test set now contains 2000 observations representing 20% of the data\n",
      "\n",
      "\u001b[1mShape of features and target\u001b[0m\n",
      "------------------------------\n",
      "Train features : (6000, 2943)\n",
      "Train target   : (6000,)\n",
      "Valid features : (2000, 2943)\n",
      "Valid target   : (2000,)\n",
      "Test features  : (2000, 2943)\n",
      "Test target    : (2000,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Surname_Abbie</th>\n",
       "      <th>...</th>\n",
       "      <th>Surname_Zotova</th>\n",
       "      <th>Surname_Zox</th>\n",
       "      <th>Surname_Zubarev</th>\n",
       "      <th>Surname_Zubareva</th>\n",
       "      <th>Surname_Zuev</th>\n",
       "      <th>Surname_Zuyev</th>\n",
       "      <th>Surname_Zuyeva</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-0.912805</td>\n",
       "      <td>-0.134048</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>-0.358372</td>\n",
       "      <td>0.076163</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>-1.550255</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.331571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>0.191250</td>\n",
       "      <td>-1.010798</td>\n",
       "      <td>0.494555</td>\n",
       "      <td>1.715473</td>\n",
       "      <td>0.136391</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>-0.727858</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>-0.450073</td>\n",
       "      <td>0.639554</td>\n",
       "      <td>1.353490</td>\n",
       "      <td>-1.395294</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>-0.477006</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.028151</td>\n",
       "      <td>-0.990168</td>\n",
       "      <td>2.116987</td>\n",
       "      <td>-1.049653</td>\n",
       "      <td>0.651725</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>-0.100232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8178</th>\n",
       "      <td>1.660092</td>\n",
       "      <td>0.567351</td>\n",
       "      <td>0.685430</td>\n",
       "      <td>0.678550</td>\n",
       "      <td>0.813110</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerId  CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
       "492    -0.912805    -0.134048 -0.078068 -0.358372  0.076163       0.816929   \n",
       "6655    0.191250    -1.010798  0.494555  1.715473  0.136391      -0.896909   \n",
       "4287   -0.450073     0.639554  1.353490 -1.395294  0.358435      -0.896909   \n",
       "42     -0.028151    -0.990168  2.116987 -1.049653  0.651725      -0.896909   \n",
       "8178    1.660092     0.567351  0.685430  0.678550  0.813110       0.816929   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Surname_Abbie  ...  \\\n",
       "492   -1.550255        0.968496         0.331571              0  ...   \n",
       "6655   0.645055        0.968496        -0.727858              0  ...   \n",
       "4287   0.645055        0.968496        -0.477006              0  ...   \n",
       "42     0.645055        0.968496        -0.100232              0  ...   \n",
       "8178   0.645055        0.968496         0.801922              0  ...   \n",
       "\n",
       "      Surname_Zotova  Surname_Zox  Surname_Zubarev  Surname_Zubareva  \\\n",
       "492                0            0                0                 0   \n",
       "6655               0            0                0                 0   \n",
       "4287               0            0                0                 0   \n",
       "42                 0            0                0                 0   \n",
       "8178               0            0                0                 0   \n",
       "\n",
       "      Surname_Zuev  Surname_Zuyev  Surname_Zuyeva  Geography_Germany  \\\n",
       "492              0              0               0                  0   \n",
       "6655             0              0               0                  0   \n",
       "4287             0              0               0                  1   \n",
       "42               0              0               0                  0   \n",
       "8178             0              0               0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "492                 0            0  \n",
       "6655                0            1  \n",
       "4287                0            1  \n",
       "42                  0            0  \n",
       "8178                0            0  \n",
       "\n",
       "[5 rows x 2943 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one-hot encoding of categorical features\n",
    "df_ohe = pd.get_dummies(df, drop_first=True) \n",
    "    \n",
    "# declare variables for features and target\n",
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop(['RowNumber', 'Exited'], axis=1)\n",
    "    \n",
    "# split data into training and testing \n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.20, random_state=12345\n",
    ")\n",
    "# split train data into validation and train \n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345\n",
    ") # 0.25 * 0.80 = 0.20 for validation size\n",
    "    \n",
    "# display the shape of the split dataset\n",
    "print('The train set now contains {}'.format(features_train.shape[0]) + ' observations representing 60% of the data') \n",
    "print('The valid set now contains {}'.format(features_valid.shape[0]) + ' observations representing 20% of the data')\n",
    "print('The test set now contains {}'.format(features_test.shape[0]) + ' observations representing 20% of the data')\n",
    "print()\n",
    "\n",
    "# numeric features in dataset\n",
    "numeric = ['CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', \n",
    "           'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# features scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "# transform the training set and the validation set using transform()\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric]  = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric]  = scaler.transform(features_valid[numeric])\n",
    "    \n",
    "print(\"\\033[1m\" + 'Shape of features and target' + \"\\033[0m\")\n",
    "print('-'*30)\n",
    "print('Train features :', features_train.shape)\n",
    "print('Train target   :',target_train.shape)\n",
    "print('Valid features :',features_valid.shape)\n",
    "print('Valid target   :',target_valid.shape)\n",
    "print('Test features  :',features_test.shape)\n",
    "print('Test target    :',target_test.shape)\n",
    "print()\n",
    "display(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "We encoded the categorical feature using one-hot encoding. By now, we have a lot of data from the one-hot encoding process. But when data is abundant, we have a chance of falling into the dummy feature trap. If we keep the features as they are now, it will hinder the training process. We have added 2936 new features to our table from the one-hot encoding process, but their high correlation will confuse our model. To avoid this, we can safely remove any one column, since its values can be easily inferred from one of the other two columns (it has 1 where the other two columns have zeroes, and it has zeroes everywhere else). This way, we will not fall into the dummy trap. Pandas library has a function pd.get_dummies() that can be used for getting dummy variables. We split the data three ways into 60% training set, 20% validation set, and 20% testing sets. Since the features have different scales, we standardized the numerical features of the data. The size of the new table is 6000 rows and 2943 columns for the train features set, 2000 rows and 2943 columns for the validation features set, and 2000 rows and 2943 columns for the test features set. Now the data is prepared and ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"class_balance\">\n",
    "    <h2>Examine the balance of classes</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model without taking into account the imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    model.score(X_train, y_train) # check the model's accuracy with score() method\n",
    "    train_predictions = model.predict(X_train) # make predictions on train set\n",
    "    predicted_valid = model.predict(X_valid) # make predictions on validation set\n",
    "    print('Accuracy for logistic regression model')\n",
    "    print('-'*40)\n",
    "    print('Training set:', accuracy_score(y_train, train_predictions))\n",
    "    print('Validation set:', accuracy_score(y_valid, predicted_valid))\n",
    "    print()\n",
    "    print('F1 score for logistic regression model')\n",
    "    print('-'*35)\n",
    "    print('F1 score: {:.3f}'.format(f1_score(y_valid, predicted_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression model\n",
      "----------------------------------------\n",
      "Training set: 0.846\n",
      "Validation set: 0.807\n",
      "\n",
      "F1 score for logistic regression model\n",
      "-----------------------------------\n",
      "F1 score: 0.308\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.9165\n",
      "1    0.0835\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train) # train the model \n",
    "predicted_valid = pd.Series(model.predict(features_valid))\n",
    "class_frequency = predicted_valid.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we trained the model without taking into account the imbalance. We achieved an accuracy of 0.807 on the validation set and an F1 score of 0.308. We assess the sanity of the model by checking how often the target feature contains the class \"1\" or \"0\". We can observe the class imbalance in the predicted validation set. Next we try to improve the quality of the model using two different approaches to fixing class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"improve_quality\">\n",
    "    <h2>Improve the quality of the model</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply two different approaches to fix the class imbalance.\n",
    "- Class weight adjustment\n",
    "- Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with adjusted class weight: 0.449\n"
     ]
    }
   ],
   "source": [
    "# class weight adjustment\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 score with adjusted class weight: {:.3f}'.format(f1_score(target_valid, predicted_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.6835\n",
      "1    0.3165\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check after class imbalance\n",
    "predicted_valid = pd.Series(model.predict(features_valid))\n",
    "class_frequency = predicted_valid.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we made the rare classes weigh more by specifying `class_weight='balanced'`. Notice how the F1 score improved to $\\approx$ 0.45. This is what class weight adjustment can achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform upsampling \n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# new training set created\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score after upsampling: 0.430\n"
     ]
    }
   ],
   "source": [
    "# F1 score after upsampling \n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 score after upsampling: {:.3f}'.format(f1_score(target_valid, predicted_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split the training sample into negative and positive observations, we duplicated the positive observations and combine them with the negative class observation. Then we shuffled the data using `shuffle()` function, and trained our *LogisticRegression* model with the new data. We calculated the F1 score to be 0.43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"investigate_models\">\n",
    "    <h2>Investigate different models quality</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree Classifier\n",
    "\n",
    "For the decision tree classifier, we iterate over different values and compare the quality of the model by tuning the `max_depth` hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decision tree classifier\n",
    "def decision_tree_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a decision tree classifier function developed to train  \n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets and plot model \n",
    "    accuracy scores on train and validation sets for visual comparison\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    # define the tree depth\n",
    "    tree_depth = [i for i in range(1, 21)]\n",
    "    # create a loop for max_depth from 1 to 21\n",
    "    for depth in tree_depth:\n",
    "        model = DecisionTreeClassifier(random_state=12345, max_depth = depth) # create an instance of a class\n",
    "        model.fit(X_train, y_train) # train the model\n",
    "        # make predictions on train set\n",
    "        train_predictions = model.predict(X_train)\n",
    "        train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "        train_scores.append(train_predictions_acc)\n",
    "        # make predictions on validation set\n",
    "        predictions_valid = model.predict(X_valid)\n",
    "        predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "        valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(tree_depth, train_scores, valid_scores))\n",
    "    print('The validation score with the best accuracy occured at' \"\\033[1m\" + ' tree depth {}'.format(max(scores, key = lambda x: x[2])[0]) + \"\\033[0m\" +\n",
    "          ' with an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[2])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[2])[2]) + ' for the validation set' + \"\\033[0m\")\n",
    "    # plot of train and validation scores vs tree depth\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(tree_depth, train_scores, '-*', label='Train')\n",
    "    plt.plot(tree_depth, valid_scores, '-o', label='Validation')\n",
    "    plt.title('Plot of train and validation scores vs tree depth')\n",
    "    plt.xlabel('Max depth')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score with the best accuracy occured at\u001b[1m tree depth 6\u001b[0m with an accuracy of \u001b[1m86.80% for the training set \u001b[0mand \u001b[1m85.80% for the validation set\u001b[0m\n",
      "F1 score: 0.449\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine accuracy for decision tree classifier\n",
    "decision_tree_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a loop for `max_depth` hyperparameter from 1 to 20 to see what depth gives us the best fit. We note that shallow decision trees (e.g. few depth) generally do not overfit but have poor performance (high bias, low variance), and deep trees (e.g. high depth) generally do overfit and have good performance (low bias, high variance). Our desirable tree depth is one that is not so shallow that it has low performance and not so deep that it overfits the training dataset. We need to have a balance between bias and variance - bias variance tradeoff. We plot the model accuracy scores on the train and validation sets to visualize this. Notice how the accuracy of the validation test keeps increasing until it gets to `max_depth` of 6. After this depth, the accuracy starts to decline. At `max_depth` of 6, we have an accuracy of 86.80% for the training set, and 85.80% for the validation set. We choose a tree depth of 6 before the model begins to overfit the training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    # define parameter \"C\" values\n",
    "    c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "    # create a for loop to loop through each C parameter values\n",
    "    for c_parameter in c_values:\n",
    "        model = LogisticRegression(random_state=12345, C=c_parameter, solver='liblinear')\n",
    "        model.fit(X_train, y_train) # train the model \n",
    "        # make predictions on train set\n",
    "        train_predictions = model.predict(X_train)\n",
    "        train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "        train_scores.append(train_predictions_acc)\n",
    "        # make predictions on validation set\n",
    "        predictions_valid = model.predict(X_valid)\n",
    "        predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "        valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(c_values, train_scores, valid_scores))\n",
    "    print('The validation score with the best accuracy occured using' \"\\033[1m\" + ' C parameter of {}'.format(max(scores, key = lambda x: x[2])[0]) + \"\\033[0m\" +\n",
    "          ' with an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[2])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[2])[2]) + ' for the validation set' + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score with the best accuracy occured using\u001b[1m C parameter of 0.1\u001b[0m with an accuracy of \u001b[1m82.03% for the training set \u001b[0mand \u001b[1m81.35% for the validation set\u001b[0m\n",
      "F1 score: 0.449\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tuned the \"C\" parameter for the logistic regression model. Although the model training is fast, the accuracy is lower. The logistic regression model gave an accuracy of 82.03% for the training set, and 81.35% for the validation sets when using a \"C\" parameter of 0.1. We can see here that neither the training nor the validation score is high enough. This is because the model is not complex enough hence underfitting occurs. Let's see how other model behave before deciding on the model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is an Adaboost classifier function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    model = AdaBoostClassifier(random_state=12345, n_estimators=5)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    model.score(X_train, y_train) # check the model's accuracy with score() method\n",
    "    train_predictions = model.predict(X_train) # make predictions on train set\n",
    "    predictions_valid = model.predict(X_valid) # make predictions on validation set\n",
    "    print('Accuracy for Adaboost classifier')\n",
    "    print('-'*40)\n",
    "    print('Training set:', accuracy_score(y_train, train_predictions))\n",
    "    print('Validation set:', accuracy_score(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Adaboost classifier\n",
      "----------------------------------------\n",
      "Training set: 0.8525\n",
      "Validation set: 0.856\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for adaboost classifier\n",
    "adaboost_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the random forest classifier model\n",
    "def random_forest_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a random forest classifier function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets and visualize\n",
    "    model accuracy scores on train and validation sets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    # define the n_estimator range\n",
    "    estimator_depth = [i for i in range(1, 21)]\n",
    "    # create a loop for n_estimator from 1 to 21\n",
    "    for estimator in estimator_depth:\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=estimator)\n",
    "        model.fit(X_train, y_train) # train the model \n",
    "        # make predictions on train set\n",
    "        train_predictions = model.predict(X_train)\n",
    "        train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "        train_scores.append(train_predictions_acc)\n",
    "        # make predictions on validation set\n",
    "        predictions_valid = model.predict(X_valid)\n",
    "        predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "        valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(estimator_depth, train_scores, valid_scores))\n",
    "    print('The validation score with the best accuracy occured using' \"\\033[1m\" + ' n_estimator of {}'.format(max(scores, key = lambda x: x[2])[0]) + \"\\033[0m\" +\n",
    "          ' with an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[2])[1]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[2])[2]) + ' for the validation set' + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score with the best accuracy occured using\u001b[1m n_estimator of 16\u001b[0m with an accuracy of \u001b[1m99.10% for the training set \u001b[0mand \u001b[1m85.35% for the validation set\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for random forest classifier\n",
    "random_forest_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stochastic Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "From the investigation of different model quality, we can see that at `n_estimators` value of 10, the random forest gives an accuracy of 98.0% for the training data, and 78.80% for the validation data. The logistic regression model was the least accurate model with an accuracy of 70.28% for the training set, and about 69.98% for the validation sets. We proceed to use the random forest classifier to test prediction on the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"check_quality\">\n",
    "    <h2>Check model quality</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sanity_check\">\n",
    "    <h2>Sanity check the model</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sMAPE \n",
    "# def smape(actual, predicted):\n",
    "#     dividend= np.abs(np.array(actual) - np.array(predicted))\n",
    "#     denominator = np.array(actual) + np.array(predicted)\n",
    "    \n",
    "#     return 2 * np.mean(np.divide(dividend, denominator, out=np.zeros_like(dividend), where=denominator!=0, casting='unsafe'))\n",
    "\n",
    "# def print_metrics(y_test, y_pred):\n",
    "#     print(\"RMSE: %.4f\" % sqrt(mean_squared_error(y_test, y_pred)))\n",
    "#     print('Variance score: %.4f' % r2_score(y_test, y_pred))\n",
    "#     print('Explained variance score: %.4f' % explained_variance_score(y_test, y_pred))\n",
    "#     forecast_err = np.array(y_test) - np.array(y_pred)\n",
    "#     print('Forecast bias: %.4f' % (np.sum(forecast_err) * 1.0/len(y_pred) ))\n",
    "#     print('sMAPE: %.4f' % smape(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"overall_conclusion\">\n",
    "    <h2>Overall conclusion</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
