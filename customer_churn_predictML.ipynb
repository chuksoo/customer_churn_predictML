{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZ_-ql1zRCIE"
   },
   "source": [
    "# Predicting Customer Churn with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwaUd1PSRCIH"
   },
   "source": [
    "Beta Bank customers are leaving: little by little, chipping away every month. The bankers figured out it’s cheaper to save the existing customers rather than to attract new ones.\n",
    "We need to predict whether a customer will leave the bank soon. You have the data on clients’ past behavior and termination of contracts with the bank. \n",
    "\n",
    "Build a model with the maximum possible F1 score. To pass the project, you need an F1 score of at least 0.59. Check the F1 for the test set. Additionally, measure the AUC-ROC metric and compare it with the F1.\n",
    "Data source: https://code.s3.yandex.net/datasets/Churn.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Qu0KCQRCII"
   },
   "source": [
    "##### Business Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kCNm5ECRCII"
   },
   "source": [
    "One of the key business metrics (along with cash flow etc.) for banks, internet providers, pay TV companies, telecom companies is customer attrition analysis (or customer churn analysis). We say customer churn is loss of clients or customers. It is cheaper to keep existing customers than go for new ones. Beta bank have already seen the effect of customer churn as it affects their end of the year revenue and monthly recurring revenue (or MRR). To this end, we need to predict whether a customer will leave a bank soon given their past relationship and behavior while operating with Beta bank. The bank hopes to deploy churn prediction models and effective retention strategies in managing customer attrition thereby preventing significant loss of revenue from defecting customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBw7aKf0RCIJ"
   },
   "source": [
    "##### Task Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJDHUmFYRCIJ"
   },
   "source": [
    "Using the customer data, train a model that predicts whether a customer will leave the bank soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNXobDuYRCIJ"
   },
   "source": [
    "## Data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0v2AEkrRCIJ"
   },
   "source": [
    "The data can be found in '/datasets/Churn.csv' file. Download the dataset. \n",
    "\n",
    "**Features**\n",
    "\n",
    " - `RowNumber` — data string index\n",
    " - `CustomerId` — unique customer identifier\n",
    " - `Surname` — surname\n",
    " - `CreditScore` — credit score\n",
    " - `Geography` — country of residence\n",
    " - `Gender` — gender\n",
    " - `Age` — age\n",
    " - `Tenure` — period of maturation for a customer’s fixed deposit (years)\n",
    " - `Balance` — account balance\n",
    " - `NumOfProducts` — number of banking products used by the customer\n",
    " - `HasCrCard` — customer has a credit card\n",
    " - `IsActiveMember` — customer’s activeness\n",
    " - `EstimatedSalary` — estimated salary\n",
    "\n",
    "**Target**\n",
    "\n",
    " - `Exited` — сustomer has left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxYpiMGxRCIK"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "The objectives of this project is to:\n",
    "- Develop a model that would predicts whether a customer will leave the bank soon\n",
    "- Build a machine learning model with the maximum possible F1 score of atleast 0.59 or higher.\n",
    "- Measure the AUC-ROC metric and compare it with the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcFqyhd8RCIK"
   },
   "source": [
    "<hr>\n",
    "\n",
    " # Table of contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#open_the_data\">Open the data file and study the general information</a></li>\n",
    "        <li><a href=\"#data_preparation\">Prepare the data</a></li>\n",
    "        <li><a href=\"#feature_engineering\">Feature engineering</a></li>\n",
    "        <li><a href=\"#class_balance\">Examine the balance of classes</a></li>\n",
    "        <li><a href=\"#improve_quality\">Improve the quality of the model</a></li>\n",
    "        <li><a href=\"#investigate_models\">Investigate different models quality</a></li>\n",
    "        <li><a href=\"#check_quality\">Check model quality</a></li>\n",
    "        <li><a href=\"#overall_conclusion\">Overall conclusion</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0N1vpRFRCIL"
   },
   "source": [
    "<div id=\"open_the_data\">\n",
    "    <h2>Open the data file and study the general information</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42v9vA68RCIL"
   },
   "source": [
    "We require the following libraries: *pandas* and *numpy* for data preprocessing and manipulation, *Scikit-Learn* for building our learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nxat2ScqRCIL",
    "outputId": "5e3bc02e-3468-4711-cc80-8ceae780515b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project libraries has been successfully been imported!\n"
     ]
    }
   ],
   "source": [
    "# import pandas and numpy for data preprocessing and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import train_test_split to split data\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pd.options.mode.chained_assignment = None # to avoid SettingWithCopyWarning after scaling\n",
    "\n",
    "# import machine learning module from the sklearn library\n",
    "from sklearn.tree import DecisionTreeClassifier # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression # import logistic regression \n",
    "from sklearn.ensemble import RandomForestClassifier # import random forest algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier # import adaboost classifier algorithm\n",
    "from catboost import CatBoostClassifier # import catboost classifier\n",
    "\n",
    "# import metrics for sanity check on model\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import sklearn utilities\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "print('Project libraries has been successfully been imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqDunOaHRCIN",
    "outputId": "049e0508-d519-4eb8-9043-1d393e9ede99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been read correctly!\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "try:\n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('C:/Users/hotty/Desktop/Practicum by Yandex/Projects/Supervised Learning/Churn.csv')\n",
    "print('Data has been read correctly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BETUVWd_RCIN"
   },
   "outputs": [],
   "source": [
    "# function to determine if columns in file have null values\n",
    "def get_percent_of_na(df, num):\n",
    "    count = 0\n",
    "    df = df.copy()\n",
    "    s = (df.isna().sum() / df.shape[0])\n",
    "    for column, percent in zip(s.index, s.values):\n",
    "        num_of_nulls = df[column].isna().sum()\n",
    "        if num_of_nulls == 0:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        print('Column {} has {:.{}%} percent of Nulls, and {} of nulls'.format(column, percent, num, num_of_nulls))\n",
    "    if count != 0:\n",
    "        print(\"\\033[1m\" + 'There are {} columns with NA.'.format(count) + \"\\033[0m\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"\\033[1m\" + 'There are no columns with NA.' + \"\\033[0m\")\n",
    "        \n",
    "# function to display general information about the dataset\n",
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    This function uses the head(), info(), describe(), shape() and duplicated() \n",
    "    methods to display the general information about the dataset.\n",
    "    \"\"\"\n",
    "    print(\"\\033[1m\" + '-'*100 + \"\\033[0m\")\n",
    "    print('Head:')\n",
    "    print()\n",
    "    display(df.head())\n",
    "    print('-'*100)\n",
    "    print('Info:')\n",
    "    print()\n",
    "    display(df.info())\n",
    "    print('-'*100)\n",
    "    print('Describe:')\n",
    "    print()\n",
    "    display(df.describe())\n",
    "    print('-'*100)\n",
    "    display(df.describe(include='object'))\n",
    "    print()\n",
    "    print('Columns with nulls:')\n",
    "    display(get_percent_of_na(df, 4))  # check this out\n",
    "    print('-'*100)\n",
    "    print('Shape:')\n",
    "    print(df.shape)\n",
    "    print('-'*100)\n",
    "    print('Duplicated:')\n",
    "    print(\"\\033[1m\" + 'We have {} duplicated rows.\\n'.format(df.duplicated().sum()) + \"\\033[0m\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L5J30KZmRCIO",
    "outputId": "9b7f095e-a4a3-43ca-c85e-c17e52f0029b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General information about the dataframe\n",
      "\u001b[1m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "Head:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Describe:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>2932</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>Smith</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>32</td>\n",
       "      <td>5014</td>\n",
       "      <td>5457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surname Geography Gender\n",
       "count    10000     10000  10000\n",
       "unique    2932         3      2\n",
       "top      Smith    France   Male\n",
       "freq        32      5014   5457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with nulls:\n",
      "Column Tenure has 9.0900% percent of Nulls, and 909 of nulls\n",
      "\u001b[1mThere are 1 columns with NA.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Shape:\n",
      "(10000, 14)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Duplicated:\n",
      "\u001b[1mWe have 0 duplicated rows.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# study the general information about the dataset \n",
    "print('General information about the dataframe')\n",
    "get_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByKFq7ZqRCIO"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "From the information about the dataset, we have 10000 rows and 14 features. Looking at the dataset, we can see that about 9% of the data is missing in the `Tenure` column. We should also note that the missing values are *missing at random (MAR)*. To handle this missing values, we could either drop them entirely since the percentage of missing values is less than 10% or replace by the median of the column. Also, we need to correct the datatype from float to int in the `Tenure`, `Balance` and `EstimatedSalary` columns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Y8rgNL5RCIP"
   },
   "source": [
    "<div id=\"data_preparation\">\n",
    "    <h2>Prepare the data</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZVLDz5yRCIP"
   },
   "source": [
    "#### Processing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A75YT4caRCIP"
   },
   "source": [
    "##### Prepare `Tenure` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qX8NPRmpRCIP"
   },
   "source": [
    "To replace missing values in the `Tenure` column, we first get the unique values of `Surname`, then get the list of possible `Tenure` for those names. We then choose a random value from the list (excluding the nan values) and assign that to the missing tenure for that surname in the dataframe. For unique surname with an empty list, we use the median of the value in the `Tenure` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "katAVk5DRCIP"
   },
   "outputs": [],
   "source": [
    "# replace missing values in the Tenure column\n",
    "# get unique values of name from this dataframe\n",
    "for surname in df['Surname'].unique().tolist():\n",
    "    # get specific 'Surname' possible Tenure\n",
    "    specific_surname_df = df[df['Surname'] == surname].dropna()['Tenure']\n",
    "    surname_tenure_list = specific_surname_df.unique().tolist()\n",
    "    # for the missing values, assign a random choice of the tenure for that surname. The default is the median of the 'Tenure'\n",
    "    if surname_tenure_list != []:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = random.choice(surname_tenure_list)\n",
    "    else:\n",
    "        df.loc[(df['Surname'] == surname) & (df['Tenure'] != df['Tenure']), 'Tenure'] = df['Tenure'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khUllxrARCIQ"
   },
   "source": [
    "We have replaced missing values in the `Tenure` column based on the condition we specified. Let's look at the statistics of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "vJoMJ0pLRCIQ",
    "outputId": "0eb66a9f-8f7e-4d2d-fb74-90babfe5bed8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.01370</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.87025</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.00000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.01370   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.87025   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.00000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.00000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.00000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.00000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.00000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the statistics of the new dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kAYWdZbRCIQ",
    "outputId": "79d42563-98c9-48ed-e48c-3494db3f40cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xNTlfSGMRCIR"
   },
   "outputs": [],
   "source": [
    "# convert data to the correct data type\n",
    "def convert_to_type(df, cols, type_val):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].astype(type_val)\n",
    "        \n",
    "convert_to_type(df, ['Surname', 'Geography', 'Gender'], str)\n",
    "convert_to_type(df, ['RowNumber', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Exited'], 'int64')\n",
    "convert_to_type(df, ['Balance', 'EstimatedSalary'], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dwu4h2tuRCIR",
    "outputId": "c95e9739-f778-4454-b6d7-0efd1ba67a9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK5vhqeKRCIS"
   },
   "source": [
    "Now we don't have any missing values and we have changed the datatype in the dataset. Replacing the missing values seems like a better option than dropping the columns with missing values. Care should be taken when replacing missing values. We don't want to create bias or variance in our dataset. The data has been cleaned and so it is ready for feature engineering and machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeDQwau1RCIS"
   },
   "source": [
    "<div id=\"feature_engineering\">\n",
    "    <h2>Feature engineering</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfDqktSIRCIT"
   },
   "source": [
    "#### Feature preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7Bbkm1CRCIT"
   },
   "source": [
    "In this section, we carry out feature engineering and one-hot encoding for the categorical features. We will use one-hot encoding to transform categorical features to numerical features. To do that we have to first create dummy variable and then apply one-hot encoding for categorical features. First, we drop unimportant features like `CustomerId`, `RowNumber` and `Surname` from the dataframe before proceeding with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unimportant features\n",
    "df = df.drop(['CustomerId', 'RowNumber', 'Surname'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "AXnnBClSRCIT",
    "outputId": "32413b30-887a-4786-f187-6c32ed03ecc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set now contains 6000 observations representing 60% of the data\n",
      "The valid set now contains 2000 observations representing 20% of the data\n",
      "The test set now contains 2000 observations representing 20% of the data\n",
      "\n",
      "\u001b[1mShape of features and target\u001b[0m\n",
      "------------------------------\n",
      "Train features : (6000, 11)\n",
      "Train target   : (6000,)\n",
      "Valid features : (2000, 11)\n",
      "Valid target   : (2000,)\n",
      "Test features  : (2000, 11)\n",
      "Test target    : (2000,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>492</td>\n",
       "      <td>-0.134048</td>\n",
       "      <td>-0.078068</td>\n",
       "      <td>-0.360863</td>\n",
       "      <td>0.076163</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>-1.550255</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.331571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6655</td>\n",
       "      <td>-1.010798</td>\n",
       "      <td>0.494555</td>\n",
       "      <td>-1.404490</td>\n",
       "      <td>0.136391</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>-0.727858</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4287</td>\n",
       "      <td>0.639554</td>\n",
       "      <td>1.353490</td>\n",
       "      <td>-1.404490</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>-0.477006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>-0.990168</td>\n",
       "      <td>2.116987</td>\n",
       "      <td>-1.056614</td>\n",
       "      <td>0.651725</td>\n",
       "      <td>-0.896909</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>-0.100232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8178</td>\n",
       "      <td>0.567351</td>\n",
       "      <td>0.685430</td>\n",
       "      <td>0.682764</td>\n",
       "      <td>0.813110</td>\n",
       "      <td>0.816929</td>\n",
       "      <td>0.645055</td>\n",
       "      <td>0.968496</td>\n",
       "      <td>0.801922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "492     -0.134048 -0.078068 -0.360863  0.076163       0.816929  -1.550255   \n",
       "6655    -1.010798  0.494555 -1.404490  0.136391      -0.896909   0.645055   \n",
       "4287     0.639554  1.353490 -1.404490  0.358435      -0.896909   0.645055   \n",
       "42      -0.990168  2.116987 -1.056614  0.651725      -0.896909   0.645055   \n",
       "8178     0.567351  0.685430  0.682764  0.813110       0.816929   0.645055   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "492         0.968496         0.331571                  0                0   \n",
       "6655        0.968496        -0.727858                  0                0   \n",
       "4287        0.968496        -0.477006                  1                0   \n",
       "42          0.968496        -0.100232                  0                0   \n",
       "8178        0.968496         0.801922                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "492             0  \n",
       "6655            1  \n",
       "4287            1  \n",
       "42              0  \n",
       "8178            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# one-hot encoding of categorical features\n",
    "df_ohe = pd.get_dummies(df, drop_first=True) \n",
    "    \n",
    "# declare variables for features and target\n",
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop(['Exited'], axis=1)\n",
    "    \n",
    "# split data into training and testing \n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.20, random_state=12345\n",
    ")\n",
    "# split train data into validation and train \n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345\n",
    ") # 0.25 * 0.80 = 0.20 for validation size\n",
    "    \n",
    "# display the shape of the split dataset\n",
    "print('The train set now contains {}'.format(features_train.shape[0]) + ' observations representing 60% of the data') \n",
    "print('The valid set now contains {}'.format(features_valid.shape[0]) + ' observations representing 20% of the data')\n",
    "print('The test set now contains {}'.format(features_test.shape[0]) + ' observations representing 20% of the data')\n",
    "print()\n",
    "\n",
    "# numeric features in dataset\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', \n",
    "           'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "# features scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "# transform the training set and the validation set using transform()\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric]  = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric]  = scaler.transform(features_valid[numeric])\n",
    "    \n",
    "print(\"\\033[1m\" + 'Shape of features and target' + \"\\033[0m\")\n",
    "print('-'*30)\n",
    "print('Train features :', features_train.shape)\n",
    "print('Train target   :',target_train.shape)\n",
    "print('Valid features :',features_valid.shape)\n",
    "print('Valid target   :',target_valid.shape)\n",
    "print('Test features  :',features_test.shape)\n",
    "print('Test target    :',target_test.shape)\n",
    "print()\n",
    "display(features_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-EhYnY4RCIU"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "We encoded the categorical feature using one-hot encoding. By now, we have a lot of data from the one-hot encoding process. But when data is abundant, we have a chance of falling into the dummy feature trap. If we keep the features as they are now, it will hinder the training process. We have added 3 new features to our table from the one-hot encoding process, but their high correlation will confuse our model. To avoid this, we can safely remove any one column, since its values can be easily inferred from one of the other two columns (it has 1 where the other two columns have zeroes, and it has zeroes everywhere else). This way, we will not fall into the dummy trap. Pandas library has a function pd.get_dummies() that can be used for getting dummy variables. We split the data three ways into 60% training set, 20% validation set, and 20% testing sets. Since the features have different scales, we standardized the numerical features of the data. The size of the new table is 6000 rows and 11 columns for the train features set, 2000 rows and 11 columns for the validation features set, and 2000 rows and 11 columns for the test features set. Now the data is prepared and ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aVQ3NOERCIU"
   },
   "source": [
    "<div id=\"class_balance\">\n",
    "    <h2>Examine the balance of classes</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDwan5pfRCIU"
   },
   "source": [
    "Here we train the model without taking into account the imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "GnS83f2VRCIU"
   },
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    model.score(X_train, y_train) # check the model's accuracy with score() method\n",
    "    train_predictions = model.predict(X_train) # make predictions on train set\n",
    "    predicted_valid = model.predict(X_valid) # make predictions on validation set\n",
    "    print('Accuracy for logistic regression model')\n",
    "    print('-'*40)\n",
    "    print('Training set:', accuracy_score(y_train, train_predictions))\n",
    "    print('Validation set:', accuracy_score(y_valid, predicted_valid))\n",
    "    print()\n",
    "    print('F1 score for logistic regression model')\n",
    "    print('-'*35)\n",
    "    print('F1 score: {:.3f}'.format(f1_score(y_valid, predicted_valid, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkaA-dD5RCIU",
    "outputId": "eb302df4-9bc5-40bf-d668-451779fd3bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression model\n",
      "----------------------------------------\n",
      "Training set: 0.813\n",
      "Validation set: 0.814\n",
      "\n",
      "F1 score for logistic regression model\n",
      "-----------------------------------\n",
      "F1 score: 0.777\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "lKEGnlssRCIV",
    "outputId": "aa8cab35-4018-4efd-d701-be8475e0235c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.9295\n",
      "1    0.0705\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train) # train the model \n",
    "predicted_valid = pd.Series(model.predict(features_valid))\n",
    "class_frequency = predicted_valid.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UmGdSfVRCIV"
   },
   "source": [
    "In this section, we trained the model without taking into account the imbalance. We achieved an accuracy of 0.807 on the validation set and an F1 score of 0.777. We assess the sanity of the model by checking how often the target feature contains the class \"1\" or \"0\". We can observe the class imbalance in the predicted validation set. Next we try to improve the quality of the model using two different approaches to fixing class imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3_-4WVnRCIV"
   },
   "source": [
    "<div id=\"improve_quality\">\n",
    "    <h2>Improve the quality of the model</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho3gKWO6RCIX"
   },
   "source": [
    "We apply two different approaches to fix the class imbalance.\n",
    "- Class weight adjustment\n",
    "- Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2xQbnWYRCIX"
   },
   "source": [
    "##### Using Class Weight Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GG0f-QIwRCIX",
    "outputId": "1fd1439f-fd77-439d-de42-0a59316d770d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with adjusted class weight: 0.736\n"
     ]
    }
   ],
   "source": [
    "# class weight adjustment\n",
    "model = LogisticRegression(random_state=12345, class_weight='balanced', solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 score with adjusted class weight: {:.3f}'.format(f1_score(target_valid, predicted_valid, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "NjwBniXkRCIX",
    "outputId": "0effa872-ca44-4838-93f0-ea5535cef782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.6345\n",
      "1    0.3655\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check after class imbalance\n",
    "predicted_valid = pd.Series(model.predict(features_valid))\n",
    "class_frequency = predicted_valid.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paH09BVdRCIY"
   },
   "source": [
    "Here, we made the rare classes weigh more by specifying `class_weight='balanced'`. Notice the F1 score is $\\approx$ 0.736. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhm377iHRCIY"
   },
   "source": [
    "##### By Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2n6byWmyRCIY"
   },
   "outputs": [],
   "source": [
    "# function to perform upsampling \n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345\n",
    "    )\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# new training set created\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IA1DQ65hRCIY",
    "outputId": "22c425ea-0cdc-480d-968f-5b4945dc134c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score after upsampling: 0.693\n"
     ]
    }
   ],
   "source": [
    "# F1 score after upsampling \n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F1 score after upsampling: {:.3f}'.format(f1_score(target_valid, predicted_valid, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dquZJ5iRCIY"
   },
   "source": [
    "First, we split the training sample into negative and positive observations, we duplicated the positive observations and combine them with the negative class observation. Then we shuffled the data using `shuffle()` function, and trained our *LogisticRegression* model with the new data. We calculated the F1 score to be $\\approx$ 0.693."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-Ecx_UDRCIZ"
   },
   "source": [
    "<div id=\"investigate_models\">\n",
    "    <h2>Investigate different models quality</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "O3xUy1fewlqa"
   },
   "outputs": [],
   "source": [
    "# function to plot ROC curve\n",
    "def plot_roc(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        \"\"\"\n",
    "        This function plots the ROC curve\n",
    "        \"\"\"\n",
    "        if not ax: fig, ax = plt.subplots(1, 1)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, preds)\n",
    "        ax.plot([0, 1], [0, 1],'r--')\n",
    "        ax.plot(fpr, tpr, lw=2, label=label)\n",
    "        ax.legend(loc='lower right')\n",
    "        ax.set_title(\n",
    "            'ROC curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(fpr, tpr):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('False Positive Rate (FPR)')\n",
    "        ax.set_ylabel('True Positive Rate (TPR)')\n",
    "        ax.annotate(f'AUC: {auc(fpr, tpr):.2}', xy=(.43, .025))\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax\n",
    "    \n",
    "# function to plot the precision-recall curve\n",
    "def plot_pr(y_test, preds, ax=None, label='model'):\n",
    "    with plt.style.context('seaborn-whitegrid'):\n",
    "        \"\"\"\n",
    "        This function is used to the precision-recall curve \n",
    "        \"\"\"\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "        if not ax: fig, ax = plt.subplots()\n",
    "        ax.plot([0, 1], [1, 0],'r--')    \n",
    "        ax.plot(recall, precision, lw=2, label=label)\n",
    "        ax.legend()\n",
    "        ax.set_title(\n",
    "            'Precision-recall curve\\n'\n",
    "            f\"\"\" AP: {average_precision_score(\n",
    "                y_test, preds, pos_label=1\n",
    "            ):.2} | \"\"\"\n",
    "            f'AUC: {auc(recall, precision):.2}'\n",
    "        )\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_xlim(-0.05, 1.05)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoilUtX_RCIZ"
   },
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvAFUoAekT2G"
   },
   "source": [
    "We are going to try and tune the hyperparameters of the following classification algorithms. A small grid searching example is given and used as a starting point for the investigation. To speed up running this section, it is best if the code is run in google colab using google's GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAuVPvo2RCIZ"
   },
   "source": [
    "##### Decision Tree Classifier\n",
    "\n",
    "For the decision tree classifier, we iterate over different values and compare the quality of the model by tuning the `max_depth` hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuf0kRw8jW98",
    "outputId": "3badc9ee-8135-4081-bad0-5aa40de8fcee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best accuracy is : \n",
      "{'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 4, 'min_samples_split': 16}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.858\n",
      "0.8828333333333334\n",
      "0.303\n",
      "[[ 334 1239]\n",
      " [ 155  272]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.21      0.32      1573\n",
      "           1       0.18      0.64      0.28       427\n",
      "\n",
      "    accuracy                           0.30      2000\n",
      "   macro avg       0.43      0.42      0.30      2000\n",
      "weighted avg       0.58      0.30      0.31      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization for Decision tree classifier\n",
    "parameters = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"max_depth\" : [2, 4, 8, 16],\n",
    "    \"min_samples_split\" : [2, 4, 8, 16],\n",
    "    \"min_samples_leaf\" : [2, 4, 6]\n",
    "    }\n",
    "classifier = DecisionTreeClassifier()\n",
    "grid = GridSearchCV(classifier, parameters, scoring='accuracy', cv=5)\n",
    "grid.fit(features_train, target_train) \n",
    "y_pred = grid.predict(features_test)\n",
    "print('The parameters combination that would give best accuracy is : ')\n",
    "print(grid.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid.best_score_))\n",
    "print(grid.score(features_train, target_train))\n",
    "print(accuracy_score(target_test, y_pred))\n",
    "print(confusion_matrix(target_test, y_pred))\n",
    "print(classification_report(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0h8Q_F1BRCIZ"
   },
   "outputs": [],
   "source": [
    "# create the decision tree classifier\n",
    "def decision_tree_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a decision tree classifier function developed to train  \n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets and plot model \n",
    "    accuracy scores on train and validation sets for visual comparison\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    model = DecisionTreeClassifier(**grid.best_params_) \n",
    "    model.fit(X_train, y_train) # train the model\n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on validation set\n",
    "    predictions_valid = model.predict(X_valid)\n",
    "    predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "    valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(train_scores, valid_scores))\n",
    "    print('The decision tree classifier had the best accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[1])[0]) + ' for the training set ' + \n",
    "          \"\\033[0m\" + 'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[1])[1]) + ' for the validation set' + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kg6hr7ZDRCIZ",
    "outputId": "7bdaf560-7197-4238-c936-3a58aea0f66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree classifier had the best accuracy of \u001b[1m88.28% for the training set \u001b[0mand \u001b[1m85.25% for the validation set\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for decision tree classifier\n",
    "decision_tree_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46AIjXpcRCIa"
   },
   "source": [
    "We created a loop for `max_depth` hyperparameter from 2 to 16 to see what depth gives us the best fit. We note that shallow decision trees (e.g. few depth) generally do not overfit but have poor performance (high bias, low variance), and deep trees (e.g. high depth) generally do overfit and have good performance (low bias, high variance). Our desirable tree depth is one that is not so shallow that it has low performance and not so deep that it overfits the training dataset. We need to have a balance between bias and variance - bias variance tradeoff. At `max_depth` of 8, we have an accuracy of 88.28% for the training set, and 85.25% for the validation set. We choose a tree depth of 8 before the model begins to overfit the training dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKDdBsG2RCIa"
   },
   "source": [
    "##### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPrS67ElSsP5",
    "outputId": "b738f2ff-286d-4f7e-94d9-31d7963855a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best accuracy is : \n",
      "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.815\n",
      "0.8161666666666667\n",
      "0.7865\n",
      "[[1573    0]\n",
      " [ 427    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      1573\n",
      "           1       0.00      0.00      0.00       427\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.39      0.50      0.44      2000\n",
      "weighted avg       0.62      0.79      0.69      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization\n",
    "\n",
    "# define parameters\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2'] # l1 lasso l2 ridge\n",
    "c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers, penalty=penalty, C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the model\n",
    "regressor = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = regressor, param_grid = grid, \n",
    "                           n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_search.fit(features_train, target_train) \n",
    "y_pred = grid_search.predict(features_test)\n",
    "print('The parameters combination that would give best accuracy is : ')\n",
    "print(grid_search.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_search.best_score_))\n",
    "print(grid_search.score(features_train, target_train))\n",
    "print(accuracy_score(target_test, y_pred))\n",
    "print(confusion_matrix(target_test, y_pred))\n",
    "print(classification_report(target_test, y_pred))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "07r70Q27RCIa"
   },
   "outputs": [],
   "source": [
    "# create the logistic regression model\n",
    "def logistic_regression(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a logistic regression model function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    model = LogisticRegression(**grid_search.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on validation set\n",
    "    predictions_valid = model.predict(X_valid)\n",
    "    predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "    valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(train_scores, valid_scores))\n",
    "    print('The validation score with the best accuracy occured using' \"\\033[1m\" + ' C parameter of {}'.format(grid_search.best_params_['C']) + \"\\033[0m\" +\n",
    "          ' and ' \"\\033[1m\" + '{} as logistic regression solver'.format(grid_search.best_params_['solver']) + \"\\033[0m\" +\n",
    "          ' giving an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[1])[0]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[1])[1]) + ' for the validation set' + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtHlakjQRCIa",
    "outputId": "cd1f9a40-147b-4886-cea3-326552122a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score with the best accuracy occured using\u001b[1m C parameter of 0.01\u001b[0m and \u001b[1mnewton-cg as logistic regression solver\u001b[0m giving an accuracy of \u001b[1m81.62% for the training set \u001b[0mand \u001b[1m81.30% for the validation set\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for logistic regression model\n",
    "logistic_regression(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVtwopghRCIa"
   },
   "source": [
    "We tuned the \"C\" parameter for the logistic regression model. Although the model training is fast, the accuracy is lower. The logistic regression model gave an accuracy of 81.62% for the training set, and 81.30% for the validation sets when using a \"C\" parameter of 0.01. We can see here that neither the training nor the validation score is high enough. This is because the model is not complex enough hence underfitting occurs. Let's see how other model behave before deciding on the model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcPWkp95RCIb"
   },
   "source": [
    "##### AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ON56CqnBRVhP"
   },
   "source": [
    "AdaBoost is challenging to configure since the algorithm has many key hyperparameters that influence the behavior of the model on the training data, and the hyperparameters interact with each other. In such as senario, it is best practice to use a grid search process to discover a configuration of the model hyperparameters that works for the given problem. In this case, we would grid search two key parameters - the number of trees used in the ensemble and the learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "sehg30tlSlQ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best accuracy is : \n",
      "{'learning_rate': 0.1, 'n_estimators': 500}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.859\n",
      "0.8641666666666666\n",
      "0.2135\n",
      "[[   0 1573]\n",
      " [   0  427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1573\n",
      "           1       0.21      1.00      0.35       427\n",
      "\n",
      "    accuracy                           0.21      2000\n",
      "   macro avg       0.11      0.50      0.18      2000\n",
      "weighted avg       0.05      0.21      0.08      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV Optimization for Adaboost\n",
    "# define the model with default hyperparameters\n",
    "model = AdaBoostClassifier()\n",
    "# define the hyperparameter to tune\n",
    "n_estimators = [10, 50, 100, 500]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# define the grid of values to search \n",
    "grid = dict(n_estimators = n_estimators, learning_rate=learning_rate)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, \n",
    "                           n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "# execute the grid search\n",
    "grid_search.fit(features_train, target_train) \n",
    "y_pred = grid_search.predict(features_test)\n",
    "print('The parameters combination that would give best accuracy is : ')\n",
    "print(grid_search.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid_search.best_score_))\n",
    "print(grid_search.score(features_train, target_train))\n",
    "print(accuracy_score(target_test, y_pred))\n",
    "print(confusion_matrix(target_test, y_pred))\n",
    "print(classification_report(target_test, y_pred))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUzCgkuvWlsd"
   },
   "source": [
    "We evaluated each combination using k-fold cross-validation and compared result using the mean score for the classification accuracy. We reported the configuration with the best score along with other configuration considered. We can see that the configuration with 500 trees and a learning rate of 0.1. We can use this figures as a guide to train and validate the model or simply run a for loop through a set parameter values and learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3D5msVSpRCIb"
   },
   "outputs": [],
   "source": [
    "# create adaboost classifier\n",
    "def adaboost_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is an Adaboost classifier function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    model = AdaBoostClassifier(**grid_search.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on validation set\n",
    "    predictions_valid = model.predict(X_valid)\n",
    "    predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "    valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(train_scores, valid_scores))\n",
    "    print('The validation score with the best accuracy occured using' \"\\033[1m\" + ' n_estimate value of {}'.format(grid_search.best_params_['n_estimators']) + \"\\033[0m\" +\n",
    "          ' and ' \"\\033[1m\" + 'learning rate of {}'.format(grid_search.best_params_['learning_rate']) + \"\\033[0m\" +\n",
    "          ' giving an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[1])[0]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[1])[1]) + ' for the validation set' + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1MOOf_z0RCIb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score with the best accuracy occured using\u001b[1m n_estimate value of 500\u001b[0m and \u001b[1mlearning rate of 0.1\u001b[0m giving an accuracy of \u001b[1m86.42% for the training set \u001b[0mand \u001b[1m85.55% for the validation set\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for adaboost classifier\n",
    "adaboost_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO5RwXJjYhB8"
   },
   "source": [
    "We tuned the `n_estimators` and the learning rate for the AdaBoost classifier resulting in an accuracy of 86.42% for the training set, and 85.55% for the validation sets when using 500 trees and a learning rate of 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsqTF4TcRCIb"
   },
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "-TrPm9xmJNpZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters combination that would give best accuracy is : \n",
      "{'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "The best accuracy achieved after parameter tuning via grid search is: 0.871\n",
      "0.8971666666666667\n",
      "0.7675\n",
      "[[1520   53]\n",
      " [ 412   15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87      1573\n",
      "           1       0.22      0.04      0.06       427\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.50      0.50      0.46      2000\n",
      "weighted avg       0.67      0.77      0.70      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter optimization for Random Forest classifier\n",
    "# define the hyperparameter to tune\n",
    "parameters = {\n",
    "    \"criterion\" : [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\" : [10, 50, 100, 200, 500],\n",
    "    \"max_depth\" : [None, 2, 4, 8, 10, 12, 16],\n",
    "    \"min_samples_split\" : [2, 4, 8, 16],\n",
    "    \"min_samples_leaf\" : [2, 4, 6]\n",
    "    }\n",
    "# define the model with default hyperparameters\n",
    "classifier = RandomForestClassifier()\n",
    "# define the grid search procedure\n",
    "grid = GridSearchCV(estimator=classifier, param_grid=parameters, \n",
    "                    cv=5, scoring='accuracy')\n",
    "# execute the grid search\n",
    "grid.fit(features_train, target_train) \n",
    "y_pred = grid.predict(features_test)\n",
    "print('The parameters combination that would give best accuracy is : ')\n",
    "print(grid.best_params_)\n",
    "print('The best accuracy achieved after parameter tuning via grid search is: {:.3f}'.format(grid.best_score_))\n",
    "print(grid.score(features_train, target_train))\n",
    "print(accuracy_score(target_test, y_pred))\n",
    "print(confusion_matrix(target_test, y_pred))\n",
    "print(classification_report(target_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "zb01edKyRCIb"
   },
   "outputs": [],
   "source": [
    "# create the random forest classifier model\n",
    "def random_forest_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a random forest classifier function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets and visualize\n",
    "    model accuracy scores on train and validation sets\n",
    "    \"\"\"\n",
    "    # define lists to collect scores\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "    model = RandomForestClassifier(**grid.best_params_)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    train_scores.append(train_predictions_acc)\n",
    "    # make predictions on validation set\n",
    "    predictions_valid = model.predict(X_valid)\n",
    "    predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "    valid_scores.append(predictions_valid_acc)\n",
    "    scores = list(zip(train_scores, valid_scores))\n",
    "    print('The validation score with the best accuracy occured using' \"\\033[1m\" + ' n_estimate value of {}'.format(grid.best_params_['n_estimators']) + \"\\033[0m\" +\n",
    "          ' and ' \"\\033[1m\" + 'maximum tree depth of {}'.format(grid.best_params_['max_depth']) + \"\\033[0m\" +\n",
    "          ' giving an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(max(scores, key = lambda x: x[1])[0]) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(max(scores, key = lambda x: x[1])[1]) + ' for the validation set' + \"\\033[0m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fGwmZiYQRCIc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation score with the best accuracy occured using\u001b[1m n_estimate value of 100\u001b[0m and \u001b[1mmaximum tree depth of 10\u001b[0m giving an accuracy of \u001b[1m89.62% for the training set \u001b[0mand \u001b[1m86.50% for the validation set\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for random forest classifier\n",
    "random_forest_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSiH7VjVZQPj"
   },
   "source": [
    "We tuned the `n_estimators` for the Random Forest classifier resulting in an accuracy of 89.62% for the training set, and 86.50% for the validation sets when using 100 trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the CatBoost classifier model\n",
    "def catboost_classifier(X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    This is a catboost classifier function developed to train\n",
    "    the model, make prediction on train and validation dataset, print\n",
    "    model accuracy for training and validation datasets and visualize\n",
    "    model accuracy scores on train and validation sets\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    # make predictions on validation set\n",
    "    predictions_valid = model.predict(X_valid)\n",
    "    predictions_valid_acc = accuracy_score(y_valid, predictions_valid)\n",
    "    print('The model has an accuracy of ' \"\\033[1m\" + '{:.2%}'.format(train_predictions_acc) + ' for the training set ' + \"\\033[0m\" + \n",
    "          'and ' + \"\\033[1m\" '{:.2%}'.format(predictions_valid_acc) + ' for the validation set' + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has an accuracy of \u001b[1m92.20% for the training set \u001b[0mand \u001b[1m87.15% for the validation set\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# determine accuracy for CatBoost algorithm\n",
    "catboost_classifier(features_train, target_train, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CatBoost classifier gave a better accuracy with 92.20% for the training set and 87.15% for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9Lev3-HRCIc"
   },
   "source": [
    "**Conclusion**\n",
    "\n",
    "From the investigation of different model quality, we can see that the CatBoost classifier gives an accuracy of 92.20% for the training data, and 87.15% for the validation data which is the best result of the five different models investigated. The logistic regression model gave the lowest accuracy prediction of the five models with an accuracy of 81.62% for the training set, and 81.30% for the validation sets. We proceed to use the CatBoost classifier to test prediction on the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o_TEmBzRCIc"
   },
   "source": [
    "<div id=\"check_quality\">\n",
    "    <h2>Check model quality</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHxqO8hf60t4"
   },
   "source": [
    "#### Model testing\n",
    "\n",
    "The result of the previous section suggested that the CatBoost classifier was perhaps the most accurate model. Using this model as our final model, we can make predictions using the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "o64PMzffRCIc"
   },
   "outputs": [],
   "source": [
    "# testing the CatBoost model quality on the test set\n",
    "def model_testing(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    This is a function developed to train the model, make prediction \n",
    "    on train dataset, use prediction to test the test dataset, print\n",
    "    model accuracy for training and test datasets and visualize\n",
    "    model accuracy scores on train and test sets\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = CatBoostClassifier(verbose=0, random_state=12345)\n",
    "    model.fit(X_train, y_train) # train the model \n",
    "    # make predictions on train set\n",
    "    train_predictions = model.predict(X_train)\n",
    "    train_predictions_acc = accuracy_score(y_train, train_predictions)\n",
    "    # make predictions on test set\n",
    "    test_predictions = model.predict(X_test)\n",
    "    test_predictions_acc = accuracy_score(y_test, test_predictions)\n",
    "    print('The test set' \"\\033[1m\" + ' accuracy score is {:.2%}'.format(test_predictions_acc) + \"\\033[0m\") \n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Confusion Matrix' + \"\\033[0m\")\n",
    "    print('-'*50)\n",
    "    print(confusion_matrix(y_test, test_predictions))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Recall: ' + \"\\033[0m\", recall_score(y_test, test_predictions))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Precision: ' + \"\\033[0m\", '{:.3f}'.format(precision_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'F1-score: ' + \"\\033[0m\", '{:.3f}'.format(f1_score(y_test, test_predictions, average='weighted')))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Accuracy Score: ' + \"\\033[0m\", '{:.2%}'.format(accuracy_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Balanced Accuracy Score: ' + \"\\033[0m\", '{:.2%}'.format(balanced_accuracy_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'ROC Score: ' + \"\\033[0m\", '{:.2%}'.format(roc_auc_score(y_test, test_predictions)))\n",
    "    print()\n",
    "    print(\"\\033[1m\" + 'Classification report' + \"\\033[0m\")\n",
    "    print('-'*50)\n",
    "    print(classification_report(y_test, test_predictions))\n",
    "    print()\n",
    "    # plot of ROC and Precision-Recall curve\n",
    "    _, axs = plt.subplots(1, 2,figsize=(10,5))\n",
    "    axs = axs.ravel()\n",
    "    plot_pr(y_test, test_predictions, ax=axs[0], label=\"CatBoostClassifier\")\n",
    "    plot_roc(y_test, test_predictions, ax=axs[1], label=\"CatBoostClassifier\")\n",
    "    plt.title('Plot of ROC and Precision-Recall curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGpkaLgqHY7F",
    "outputId": "42749ff2-0cba-483c-ab11-6e6d346e5651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test set\u001b[1m accuracy score is 61.65%\u001b[0m\n",
      "\n",
      "\u001b[1mConfusion Matrix\u001b[0m\n",
      "--------------------------------------------------\n",
      "[[1147  426]\n",
      " [ 341   86]]\n",
      "\n",
      "\u001b[1mRecall: \u001b[0m 0.20140515222482436\n",
      "\n",
      "\u001b[1mPrecision: \u001b[0m 0.168\n",
      "\n",
      "\u001b[1mF1-score: \u001b[0m 0.629\n",
      "\n",
      "\u001b[1mAccuracy Score: \u001b[0m 61.65%\n",
      "\n",
      "\u001b[1mBalanced Accuracy Score: \u001b[0m 46.53%\n",
      "\n",
      "\u001b[1mROC Score: \u001b[0m 46.53%\n",
      "\n",
      "\u001b[1mClassification report\u001b[0m\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      1573\n",
      "           1       0.17      0.20      0.18       427\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.47      0.47      0.47      2000\n",
      "weighted avg       0.64      0.62      0.63      2000\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test model and check metrics\n",
    "model_testing(features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnWd1CXl9qgP"
   },
   "source": [
    "Using the CatBoost model, we obtained an accuracy score of 61.65% and an **F1-score of 0.629**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u6Q8LBIRCId"
   },
   "source": [
    "<div id=\"overall_conclusion\">\n",
    "    <h2>Overall conclusion</h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first section, we downloaded and prepared the data. From the information about the dataset, we have 10000 rows and 14 features. Looking at the dataset, we observed that about 9% of the data is missing in the Tenure column, and the data is missing at random (MAR). We replaced the missing values, corrected the datatype, and encoded the categorical feature using one-hot encoding. We splitted the data three ways into 60% training set, 20% validation set, and 20% testing sets. Since the features have different scales, we standardized the numerical features of the data. The size of the new table is 6000 rows and 11 columns for the train features set, 2000 rows and 11 columns for the validation features set, and 2000 rows and 11 columns for the test features set. \n",
    "\n",
    "We trained the model without taking into account the imbalance. We achieved an accuracy of 0.807 on the validation set and an F1 score of 0.777. We assess the sanity of the model by checking how often the target feature contains the class \"1\" or \"0\". We observed the class imbalance in the predicted validation set. Next we try to improve the quality of the model using two different approaches to fixing class imbalance. First, we split the training sample into negative and positive observations, we duplicated the positive observations and combine them with the negative class observation. Then we shuffled the data using shuffle() function, and trained our LogisticRegression model with the new data. We calculated the F1 score to be 0.693.\n",
    "\n",
    "We investigated several models and tuned different hyperparameters for those model using GridSearchCV and RepeatedStratifiedKFold. From the investigation of different model quality, we observed that the CatBoost classifier gave an accuracy of 92.20% for the training data, and 87.15% for the validation data which is the best result of the five different models investigated. The logistic regression model gave the lowest accuracy prediction of the five models with an accuracy of 81.62% for the training set, and 81.30% for the validation sets. We proceed to use the CatBoost classifier to perform the final test prediction on the unseen test data. Using the CatBoost model, we obtained an accuracy score of 61.65% on the test set, and an F1-score of 0.629. \n",
    "\n",
    "At the end of this project, we were able to predict whether a customer will leave the bank soon with an accuracy of 62% and an F1-score of 0.629. We measured the AUC score as 0.27 which is lower than the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1068,
    "start_time": "2021-07-03T03:55:59.432Z"
   },
   {
    "duration": 161,
    "start_time": "2021-07-03T03:56:01.348Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T03:56:02.636Z"
   },
   {
    "duration": 99,
    "start_time": "2021-07-03T03:56:04.249Z"
   },
   {
    "duration": 12159,
    "start_time": "2021-07-03T03:56:08.882Z"
   },
   {
    "duration": 35,
    "start_time": "2021-07-03T03:56:21.042Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T03:56:21.079Z"
   },
   {
    "duration": 23,
    "start_time": "2021-07-03T03:56:21.086Z"
   },
   {
    "duration": 16,
    "start_time": "2021-07-03T03:56:21.110Z"
   },
   {
    "duration": 536,
    "start_time": "2021-07-03T03:56:26.196Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-03T03:56:31.159Z"
   },
   {
    "duration": 714,
    "start_time": "2021-07-03T03:56:32.042Z"
   },
   {
    "duration": 699,
    "start_time": "2021-07-03T03:56:32.843Z"
   },
   {
    "duration": 312,
    "start_time": "2021-07-03T03:56:43.134Z"
   },
   {
    "duration": 513,
    "start_time": "2021-07-03T03:56:43.448Z"
   },
   {
    "duration": 264,
    "start_time": "2021-07-03T03:56:43.963Z"
   },
   {
    "duration": 612,
    "start_time": "2021-07-03T03:56:44.229Z"
   },
   {
    "duration": 98,
    "start_time": "2021-07-03T03:56:44.844Z"
   },
   {
    "duration": 141238,
    "start_time": "2021-07-03T03:56:56.627Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-03T03:59:17.868Z"
   },
   {
    "duration": 421,
    "start_time": "2021-07-03T03:59:17.875Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-03T03:59:40.139Z"
   },
   {
    "duration": 408,
    "start_time": "2021-07-03T03:59:41.020Z"
   },
   {
    "duration": -1587,
    "start_time": "2021-07-03T04:09:15.763Z"
   },
   {
    "duration": -1826,
    "start_time": "2021-07-03T04:09:16.003Z"
   },
   {
    "duration": -1830,
    "start_time": "2021-07-03T04:09:16.007Z"
   },
   {
    "duration": -1831,
    "start_time": "2021-07-03T04:09:16.009Z"
   },
   {
    "duration": -1833,
    "start_time": "2021-07-03T04:09:16.012Z"
   },
   {
    "duration": -1834,
    "start_time": "2021-07-03T04:09:16.014Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T04:09:18.664Z"
   },
   {
    "duration": 93,
    "start_time": "2021-07-03T04:09:20.591Z"
   },
   {
    "duration": 1031,
    "start_time": "2021-07-03T04:09:40.316Z"
   },
   {
    "duration": 83,
    "start_time": "2021-07-03T04:09:41.349Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:09:44.720Z"
   },
   {
    "duration": 85,
    "start_time": "2021-07-03T04:09:45.501Z"
   },
   {
    "duration": 12217,
    "start_time": "2021-07-03T04:09:51.495Z"
   },
   {
    "duration": 41,
    "start_time": "2021-07-03T04:10:03.714Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:10:03.757Z"
   },
   {
    "duration": 14,
    "start_time": "2021-07-03T04:10:03.764Z"
   },
   {
    "duration": 9,
    "start_time": "2021-07-03T04:10:03.779Z"
   },
   {
    "duration": 515,
    "start_time": "2021-07-03T04:10:51.649Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-03T04:12:01.058Z"
   },
   {
    "duration": 67,
    "start_time": "2021-07-03T04:12:01.560Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:12:02.323Z"
   },
   {
    "duration": 86,
    "start_time": "2021-07-03T04:12:02.858Z"
   },
   {
    "duration": 12414,
    "start_time": "2021-07-03T04:12:05.339Z"
   },
   {
    "duration": 32,
    "start_time": "2021-07-03T04:12:17.755Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-03T04:12:17.789Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-03T04:12:17.796Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-03T04:12:17.808Z"
   },
   {
    "duration": 440,
    "start_time": "2021-07-03T04:12:23.643Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-03T04:12:48.088Z"
   },
   {
    "duration": 469,
    "start_time": "2021-07-03T04:13:21.081Z"
   },
   {
    "duration": 247,
    "start_time": "2021-07-03T04:15:27.325Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-03T04:15:44.773Z"
   },
   {
    "duration": 54,
    "start_time": "2021-07-03T04:16:30.220Z"
   },
   {
    "duration": 1162,
    "start_time": "2021-07-03T04:17:00.420Z"
   },
   {
    "duration": 80,
    "start_time": "2021-07-03T04:17:02.112Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:17:03.013Z"
   },
   {
    "duration": 90,
    "start_time": "2021-07-03T04:17:03.651Z"
   },
   {
    "duration": 12064,
    "start_time": "2021-07-03T04:17:13.073Z"
   },
   {
    "duration": 33,
    "start_time": "2021-07-03T04:17:25.141Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:17:25.176Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-03T04:17:25.183Z"
   },
   {
    "duration": 20,
    "start_time": "2021-07-03T04:17:25.196Z"
   },
   {
    "duration": 11,
    "start_time": "2021-07-03T04:19:18.333Z"
   },
   {
    "duration": 54,
    "start_time": "2021-07-03T04:21:28.706Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-03T04:24:29.885Z"
   },
   {
    "duration": 24,
    "start_time": "2021-07-03T04:24:32.255Z"
   },
   {
    "duration": 312,
    "start_time": "2021-07-03T04:24:38.136Z"
   },
   {
    "duration": 19,
    "start_time": "2021-07-03T04:24:46.825Z"
   },
   {
    "duration": 317,
    "start_time": "2021-07-03T04:25:23.531Z"
   },
   {
    "duration": 12,
    "start_time": "2021-07-03T04:25:52.668Z"
   },
   {
    "duration": 29,
    "start_time": "2021-07-03T04:25:53.115Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:26:32.041Z"
   },
   {
    "duration": 6441,
    "start_time": "2021-07-03T04:26:35.376Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-03T04:26:41.818Z"
   },
   {
    "duration": 41,
    "start_time": "2021-07-03T04:26:41.824Z"
   },
   {
    "duration": 109474,
    "start_time": "2021-07-03T04:29:16.075Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-03T04:31:05.642Z"
   },
   {
    "duration": 298,
    "start_time": "2021-07-03T04:31:05.648Z"
   },
   {
    "duration": 383467,
    "start_time": "2021-07-03T04:31:23.220Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T04:37:46.689Z"
   },
   {
    "duration": 2340,
    "start_time": "2021-07-03T04:37:46.697Z"
   },
   {
    "duration": 2740925,
    "start_time": "2021-07-03T04:42:09.505Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-03T05:27:50.432Z"
   },
   {
    "duration": 642,
    "start_time": "2021-07-03T05:27:50.442Z"
   },
   {
    "duration": 132,
    "start_time": "2021-07-03T05:27:51.086Z"
   },
   {
    "duration": -276,
    "start_time": "2021-07-03T05:27:51.495Z"
   },
   {
    "duration": -282,
    "start_time": "2021-07-03T05:27:51.502Z"
   },
   {
    "duration": 376,
    "start_time": "2021-07-03T05:28:21.303Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-03T05:28:22.448Z"
   },
   {
    "duration": 296,
    "start_time": "2021-07-03T05:31:36.920Z"
   },
   {
    "duration": -979,
    "start_time": "2021-07-03T08:21:16.229Z"
   },
   {
    "duration": -986,
    "start_time": "2021-07-03T08:21:16.237Z"
   },
   {
    "duration": -987,
    "start_time": "2021-07-03T08:21:16.240Z"
   },
   {
    "duration": 42,
    "start_time": "2021-07-03T08:32:51.150Z"
   },
   {
    "duration": 20063,
    "start_time": "2021-07-03T08:33:28.060Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T08:45:59.944Z"
   },
   {
    "duration": 267,
    "start_time": "2021-07-03T08:46:00.906Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-03T08:48:39.075Z"
   },
   {
    "duration": 19012,
    "start_time": "2021-07-03T08:48:39.712Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T08:49:46.079Z"
   },
   {
    "duration": 18517,
    "start_time": "2021-07-03T08:49:46.598Z"
   },
   {
    "duration": 527,
    "start_time": "2021-07-03T08:51:19.501Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T08:54:01.368Z"
   },
   {
    "duration": 1076,
    "start_time": "2021-07-03T08:54:08.586Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T08:56:29.106Z"
   },
   {
    "duration": 578,
    "start_time": "2021-07-03T08:56:35.789Z"
   },
   {
    "duration": 499,
    "start_time": "2021-07-03T08:57:17.525Z"
   },
   {
    "duration": 548,
    "start_time": "2021-07-03T09:05:09.139Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T09:05:36.597Z"
   },
   {
    "duration": 21948,
    "start_time": "2021-07-03T09:05:37.852Z"
   },
   {
    "duration": 6,
    "start_time": "2021-07-03T09:06:54.202Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T09:07:04.223Z"
   },
   {
    "duration": 20313,
    "start_time": "2021-07-03T09:07:05.391Z"
   },
   {
    "duration": 17,
    "start_time": "2021-07-03T09:21:26.727Z"
   },
   {
    "duration": 93,
    "start_time": "2021-07-03T09:26:27.847Z"
   },
   {
    "duration": 94,
    "start_time": "2021-07-03T09:27:34.249Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-03T09:28:08.311Z"
   },
   {
    "duration": 18996,
    "start_time": "2021-07-03T09:28:12.892Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-03T09:36:42.989Z"
   },
   {
    "duration": 69,
    "start_time": "2021-07-03T09:36:43.471Z"
   },
   {
    "duration": 17,
    "start_time": "2021-07-03T09:37:30.561Z"
   },
   {
    "duration": 25,
    "start_time": "2021-07-03T09:37:48.338Z"
   },
   {
    "duration": 10,
    "start_time": "2021-07-03T10:04:00.418Z"
   }
  ],
  "accelerator": "TPU",
  "colab": {
   "name": "customer_churn_predictML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
